{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fde45b7b",
   "metadata": {},
   "source": [
    "## Agent With Text to Cypher, Hybrid (Vector Index + GDS) Retrieval Via MCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44c634ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "from expert_tools import ExpertTools\n",
    "\n",
    "#get env setup\n",
    "load_dotenv('podcast-gds.env', override=True)\n",
    "\n",
    "if not os.environ.get('NEO4J_URI'):\n",
    "    os.environ['NEO4J_URI'] = getpass.getpass('NEO4J_URI:\\n')\n",
    "if not os.environ.get('NEO4J_USERNAME'):\n",
    "    os.environ['NEO4J_USERNAME'] = getpass.getpass('NEO4J_USERNAME:\\n')\n",
    "if not os.environ.get('NEO4J_PASSWORD'):\n",
    "    os.environ['NEO4J_PASSWORD'] = getpass.getpass('NEO4J_PASSWORD:\\n')\n",
    "\n",
    "NEO4J_URI = os.getenv('NEO4J_URI')\n",
    "NEO4J_USERNAME = os.getenv('NEO4J_USERNAME')\n",
    "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29eebbce",
   "metadata": {},
   "source": [
    "#### Verify presence of VectorIndex, chunkIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57805079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Verifying presence of vector index 'chunkIndex'...\n",
      "   Connecting to: neo4j+s://2236ba22.databases.neo4j.io\n",
      "\n",
      "âœ… Found 1 vector index(es):\n",
      "\n",
      "- chunkIndex (state: ONLINE)\n",
      "\n",
      "âœ… Confirmed: 'chunkIndex' exists and is visible from this connection.\n",
      "   State: ONLINE\n",
      "\n",
      "âœ… Check complete.\n"
     ]
    }
   ],
   "source": [
    "# Verify vector index exists before creating the agent (no creation)\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "print(\"ðŸ” Verifying presence of vector index 'chunkIndex'...\")\n",
    "print(f\"   Connecting to: {NEO4J_URI}\")\n",
    "print()\n",
    "\n",
    "expert_temp = ExpertTools()\n",
    "\n",
    "with expert_temp.driver.session() as session:\n",
    "    result = session.run(\"SHOW VECTOR INDEXES\")\n",
    "    indexes = [record.data() for record in result]\n",
    "\n",
    "    if not indexes:\n",
    "        print(\"âš ï¸  No vector indexes found.\")\n",
    "    else:\n",
    "        print(f\"âœ… Found {len(indexes)} vector index(es):\\n\")\n",
    "        for idx in indexes:\n",
    "            print(f\"- {idx.get('name', 'N/A')} (state: {idx.get('state', 'N/A')})\")\n",
    "\n",
    "    chunk_index = [idx for idx in indexes if idx.get('name') == 'chunkIndex']\n",
    "    if chunk_index:\n",
    "        print(f\"\\nâœ… Confirmed: 'chunkIndex' exists and is visible from this connection.\")\n",
    "        print(f\"   State: {chunk_index[0].get('state', 'unknown')}\")\n",
    "    else:\n",
    "        print(f\"\\nâŒ 'chunkIndex' not found from this connection.\")\n",
    "        print(\"   If it exists elsewhere, check that:\")\n",
    "        print(\"   - You're connecting to the same database (URI and database name)\")\n",
    "        print(\"   - The user has privileges to see the index\")\n",
    "\n",
    "expert_temp.close()\n",
    "print(\"\\nâœ… Check complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bda3e899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session started successfully with ID: 7b49d662-d322-43ac-a7fe-2a82da2ec903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from AgentRunner import AgentRunner\n",
    "import importlib\n",
    "import expert_tools\n",
    "\n",
    "# Reload the module to pick up the latest changes (fixes module caching issue)\n",
    "importlib.reload(expert_tools)\n",
    "from expert_tools import ExpertTools\n",
    "\n",
    "# build adk agent with neo4j mcp\n",
    "from neo4j_podcast_episode import PersonRel, PodcastEpisodeRel, EpisodeTopicRel, EpisodeChunkRel, TopicConceptRel, TopicTechnologyRel\n",
    "from google.adk.models.lite_llm import LiteLlm\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.tools.mcp_tool.mcp_toolset import McpToolset, StdioConnectionParams, StdioServerParameters\n",
    "from prompts import MENTAL_MODEL_AI_INSTRUCTION\n",
    "\n",
    "\n",
    "expert = ExpertTools()\n",
    "database_agent = Agent(\n",
    "    name=\"graph_database_agent\",\n",
    "    # model=\"gemini-2.0-flash-exp\",\n",
    "    model=LiteLlm(model=\"openai/gpt-4.1-mini\"),\n",
    "    # model=LiteLlm(model=\"anthropic/claude-sonnet-4-20250514\"),\n",
    "    description=\"\"\"\n",
    "    Agent to access knowledge graph stored in graph database\n",
    "    \"\"\",\n",
    "    instruction=MENTAL_MODEL_AI_INSTRUCTION,\n",
    "    tools=[expert.search_episodes_gds_by_question_tool,\n",
    "           expert.find_episodes_by_people,\n",
    "           expert.find_episodes_by_concept,\n",
    "           expert.find_episodes_by_technology,\n",
    "           expert.find_episodes_by_topic,\n",
    "           McpToolset(\n",
    "        connection_params=StdioConnectionParams(\n",
    "            server_params=StdioServerParameters(\n",
    "                command='uvx',\n",
    "                args=['mcp-neo4j-cypher'],\n",
    "                env={ k: os.environ[k] for k in [\"NEO4J_URI\",\"NEO4J_USERNAME\",\"NEO4J_PASSWORD\"] }\n",
    "            )\n",
    "        ),\n",
    "        tool_filter=['get_neo4j_schema','read_neo4j_cypher']\n",
    "    )]\n",
    ")\n",
    "\n",
    "\n",
    "db_agent_runner = AgentRunner(app_name='db_agent', user_id='Sang', agent=database_agent)\n",
    "await db_agent_runner.start_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c672db31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95bab4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sangeethar/workspace/AI-Workspace/neo4j-employee-graph/neo4j-employee-graph/.venv/lib/python3.12/site-packages/google/adk/tools/mcp_tool/mcp_tool.py:88: UserWarning: [EXPERIMENTAL] BaseAuthenticatedTool: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  super().__init__(\n",
      "auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
      "auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
      "auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None id='call_2MKj39yy4Jz1DwVs8usV954Q' args={'query': 'MATCH (p:Person)-[r]->(e:Episode)-[:HAS_TOPIC]->(t:Topic) WHERE p.name = $personName RETURN t.name AS topic, count(*) AS freq ORDER BY freq DESC LIMIT 10'} name='read_neo4j_cypher' None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
      "auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
      "auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None will_continue=None scheduling=None id='call_2MKj39yy4Jz1DwVs8usV954Q' name='read_neo4j_cypher' response={'result': CallToolResult(meta=None, content=[TextContent(type='text', text='Neo4j Error: {neo4j_code: Neo.ClientError.Statement.ParameterMissing} {message: Expected parameter(s): personName} {gql_status: 42001} {gql_status_description: error: syntax error or access rule violation - invalid syntax}\\nMATCH (p:Person)-[r]->(e:Episode)-[:HAS_TOPIC]->(t:Topic) WHERE p.name = $personName RETURN t.name AS topic, count(*) AS freq ORDER BY freq DESC LIMIT 10\\n{}', annotations=None, meta=None)], structuredContent=None, isError=True)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
      "auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
      "auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None id='call_PY8vrz6tmeBvsRvHTm47e2Dh' args={'query': \"MATCH (p:Person)-[r]->(e:Episode)-[:HAS_TOPIC]->(t:Topic) WHERE p.name CONTAINS 'Sangeetha' RETURN t.name AS topic, count(*) AS freq ORDER BY freq DESC LIMIT 10\"} name='read_neo4j_cypher' None\n",
      "None None will_continue=None scheduling=None id='call_PY8vrz6tmeBvsRvHTm47e2Dh' name='read_neo4j_cypher' response={'result': CallToolResult(meta=None, content=[TextContent(type='text', text='[{\"topic\": \"Delayed View Semantics and Incremental Processing\", \"freq\": 2}, {\"topic\": \"Model Context Protocol (MCP): The Open Standard for Context-Aware AI\", \"freq\": 2}, {\"topic\": \"Duck Lake: The SQL-Backed Open Standard for Simplified Lakehouse Metadata\", \"freq\": 2}, {\"topic\": \"Embeddable Graph Databases with KuzuDB\", \"freq\": 2}, {\"topic\": \"BAML: Prompts as Structured Functions\", \"freq\": 2}, {\"topic\": \"Apache Iceberg Table Format and Data Lakes\", \"freq\": 2}]', annotations=None, meta=None)], structuredContent=None, isError=False)}\n",
      "The most commonly discussed topics across the episodes that Sangeetha Ramadurai has been focusing on in the last one month are as follows, each appearing with equal frequency in 2 episodes:\n",
      "\n",
      "- Delayed View Semantics and Incremental Processing\n",
      "- Model Context Protocol (MCP): The Open Standard for Context-Aware AI\n",
      "- Duck Lake: The SQL-Backed Open Standard for Simplified Lakehouse Metadata\n",
      "- Embeddable Graph Databases with KuzuDB\n",
      "- BAML: Prompts as Structured Functions\n",
      "- Apache Iceberg Table Format and Data Lakes\n",
      "\n",
      "These topics clearly reflect her interest in advanced data processing techniques, AI protocols, new lakehouse standards, graph database technology, and AI prompt structuring.\n",
      "\n",
      "Would you like detailed explanations or learning summaries on any of these specific topics? None None\n"
     ]
    }
   ],
   "source": [
    "user_question = \"What is the most commnly discussed topic across the episodes?\"\n",
    "res = await db_agent_runner.run(user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7044bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sangeethar/workspace/AI-Workspace/neo4j-employee-graph/neo4j-employee-graph/.venv/lib/python3.12/site-packages/google/adk/tools/mcp_tool/mcp_tool.py:88: UserWarning: [EXPERIMENTAL] BaseAuthenticatedTool: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  super().__init__(\n",
      "auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
      "auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
      "auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None id='call_iBnxOBV12PMAz3mqiO2rQSF8' args={'question': 'Sangeetha'} name='find_episodes_by_people' None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
      "auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
      "auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None will_continue=None scheduling=None id='call_iBnxOBV12PMAz3mqiO2rQSF8' name='find_episodes_by_people' response={'result': '[\\n  {\\n    \"person_name\": \"Sangeetha Ramadurai\",\\n    \"relationship_type\": \"LEARNING_FROM\",\\n    \"episode_name\": \"Prompts as Functions: The BAML Revolution in AI Engineering\",\\n    \"episode_number\": 2025040307,\\n    \"episode_link\": \"https://thedataexchange.media/baml-revolution-in-ai-engineering/\",\\n    \"matched_term\": \"Sangeetha\"\\n  },\\n  {\\n    \"person_name\": \"Sangeetha Ramadurai\",\\n    \"relationship_type\": \"LISTENS_TO_EPISODE\",\\n    \"episode_name\": \"Prompts as Functions: The BAML Revolution in AI Engineering\",\\n    \"episode_number\": 2025040307,\\n    \"episode_link\": \"https://thedataexchange.media/baml-revolution-in-ai-engineering/\",\\n    \"matched_term\": \"Sangeetha\"\\n  },\\n  {\\n    \"person_name\": \"Sangeetha Ramadurai\",\\n    \"relationship_type\": \"LEARNING_FROM\",\\n    \"episode_name\": \"Anthropic And Model Context Protocol (MCP) With David Soria Parra\",\\n    \"episode_number\": 1836,\\n    \"episode_link\": \"https://www.dataengineeringpodcast.com/episodepage/anthropic-model-context-protocol-mcp-david-soria-parra-episode-1836\",\\n    \"matched_term\": \"Sangeetha\"\\n  },\\n  {\\n    \"person_name\": \"Sangeetha Ramadurai\",\\n    \"relationship_type\": \"LISTENS_TO_EPISODE\",\\n    \"episode_name\": \"Anthropic And Model Context Protocol (MCP) With David Soria Parra\",\\n    \"episode_number\": 1836,\\n    \"episode_link\": \"https://www.dataengineeringpodcast.com/episodepage/anthropic-model-context-protocol-mcp-david-soria-parra-episode-1836\",\\n    \"matched_term\": \"Sangeetha\"\\n  },\\n  {\\n    \"person_name\": \"Sangeetha Ramadurai\",\\n    \"relationship_type\": \"LISTENS_TO_EPISODE\",\\n    \"episode_name\": \"Iceberg at Netflix and Beyond with Ryan Blue\",\\n    \"episode_number\": 1654,\\n    \"episode_link\": \"https://podcasts.apple.com/us/podcast/iceberg-at-netflix-and-beyond-with-ryan-blue/id1232093653?i=1000648333293\",\\n    \"matched_term\": \"Sangeetha\"\\n  },\\n  {\\n    \"person_name\": \"Sangeetha Ramadurai\",\\n    \"relationship_type\": \"LEARNING_FROM\",\\n    \"episode_name\": \"Iceberg at Netflix and Beyond with Ryan Blue\",\\n    \"episode_number\": 1654,\\n    \"episode_link\": \"https://podcasts.apple.com/us/podcast/iceberg-at-netflix-and-beyond-with-ryan-blue/id1232093653?i=1000648333293\",\\n    \"matched_term\": \"Sangeetha\"\\n  },\\n  {\\n    \"person_name\": \"Sangeetha Ramadurai\",\\n    \"relationship_type\": \"LISTENS_TO_EPISODE\",\\n    \"episode_name\": \"Simplifying Lakehouse Ecosystem With DuckLake\",\\n    \"episode_number\": 480,\\n    \"episode_link\": \"https://www.dataengineeringpodcast.com/ducklake-easy-data-lakehouse-format-episode-480\",\\n    \"matched_term\": \"Sangeetha\"\\n  },\\n  {\\n    \"person_name\": \"Sangeetha Ramadurai\",\\n    \"relationship_type\": \"LEARNING_FROM\",\\n    \"episode_name\": \"Simplifying Lakehouse Ecosystem With DuckLake\",\\n    \"episode_number\": 480,\\n    \"episode_link\": \"https://www.dataengineeringpodcast.com/ducklake-easy-data-lakehouse-format-episode-480\",\\n    \"matched_term\": \"Sangeetha\"\\n  },\\n  {\\n    \"person_name\": \"Sangeetha Ramadurai\",\\n    \"relationship_type\": \"LEARNING_FROM\",\\n    \"episode_name\": \"High Performance And Low Overhead Graphs With KuzuDB\",\\n    \"episode_number\": 477,\\n    \"episode_link\": \"https://www.dataengineeringpodcast.com/episodepage/kuzudb-embedded-graph-database-episode-477\",\\n    \"matched_term\": \"Sangeetha\"\\n  },\\n  {\\n    \"person_name\": \"Sangeetha Ramadurai\",\\n    \"relationship_type\": \"LISTENS_TO_EPISODE\",\\n    \"episode_name\": \"High Performance And Low Overhead Graphs With KuzuDB\",\\n    \"episode_number\": 477,\\n    \"episode_link\": \"https://www.dataengineeringpodcast.com/episodepage/kuzudb-embedded-graph-database-episode-477\",\\n    \"matched_term\": \"Sangeetha\"\\n  }\\n]'}\n",
      "In the last one month, Sangeetha Ramadurai has been focusing on learning and listening to several key topics, as reflected in her recent episode engagements. Her focus areas and learning include:\n",
      "\n",
      "- AI Engineering advancements, especially through the episode \"Prompts as Functions: The BAML Revolution in AI Engineering.\"\n",
      "- Model Context Protocol (MCP) and AI safety research, as discussed in \"Anthropic And Model Context Protocol (MCP) With David Soria Parra.\"\n",
      "- Data lakehouse and big data formats, particularly through \"Iceberg at Netflix and Beyond with Ryan Blue.\"\n",
      "- Simplifying lakehouse ecosystems, explored in the episode \"Simplifying Lakehouse Ecosystem With DuckLake.\"\n",
      "- High performance graph databases, focusing on embedded graph solutions, from \"High Performance And Low Overhead Graphs With KuzuDB.\"\n",
      "\n",
      "These topics span AI prompt engineering, advanced AI models, modern big data architectures, and graph database technologies.\n",
      "\n",
      "If you'd like, I can provide more detailed summaries or insights from these episodes. None None\n"
     ]
    }
   ],
   "source": [
    "user_question = \"What has sangeetha been focussing on in the last one month. Give bulleted list of her focus areas and learning\"\n",
    "res = await db_agent_runner.run(user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf06ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_qusestion = \"What are the top 3 AI related content Sangeetha is interested in based on the content covered in various episodes?\" \n",
    "res = await db_agent_runner.run(user_qusestion)\n",
    "display(Markdown(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1ae247",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_qusestion = \"What are the top 20 technologies Sangeetha is interested in based on the content covered in various episodes?\" \n",
    "res = await db_agent_runner.run(user_qusestion)\n",
    "\n",
    "display(Markdown(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe9046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_qusestion = \"What are the top 10 Databases that are covered across episodes?\" \n",
    "res = await db_agent_runner.run(user_qusestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419d055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"Gather and synthesize more detailed notes from relevant episodes that mention Iceberg or related lakehouse technologies to provide a broader landscape view\"\n",
    "res = await db_agent_runner.run(user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561e289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"Summarize discussions around Apache Iceberg\"\n",
    "res = await db_agent_runner.run(user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5cb23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"What is Apache Iceberg and how does it work?\"\n",
    "res = await db_agent_runner.run(user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f693a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_qusestion = \"What are the top 2 episodes that cover Data Lake concepts\" \n",
    "res = await db_agent_runner.run(user_qusestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80042c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mcp\n",
    "!which mcp-neo4j-cypher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f75a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!which uvx\n",
    "!uvx --version\n",
    "!uvx mcp-neo4j-cypher --help\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5065b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = await db_agent_runner.run(\"what is Sangeetha Ramadurai learning now?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c844d76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = await db_agent_runner.run(\"What topics are discussed in the episodes?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01754c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = await db_agent_runner.run(\"How many episodes do I have?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dfbf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = await db_agent_runner.run(\"Summarize snowflake capabilities discussed in the episodes?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10625b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_episodes_discussing_topics\n",
    "res = await db_agent_runner.run(\"Find episodes discussing database and return one liner about the episode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab24bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = await db_agent_runner.run(\"Find episodes with reference linking them to any database e.g. snowflake, kuzu, etc. and return one liner about the episode\")\n",
    "\n",
    "display(Markdown(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c43e104",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = await db_agent_runner.run(\"Find episodes where snowflake is referenced\")\n",
    "\n",
    "display(Markdown(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2952f14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67af17af",
   "metadata": {},
   "source": [
    "## Adding Expert Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ec6bc5",
   "metadata": {},
   "source": [
    "### Tool - Ask free form question for Vector + graph response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1587796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the new Vector + Graph Search Tool\n",
    "print(\"Testing Vector + Graph Search Tool...\")\n",
    "res = await db_agent_runner.run(\"How does KuzuDB improve performance in graph databases? Use the vector search tool to find relevant content.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5e772e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e652e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test search methods with JSON formatting\n",
    "import json\n",
    "from expert_tools import ExpertTools\n",
    "\n",
    "expert = ExpertTools()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14e29e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the specific method you're using\n",
    "print(\"=== Testing find_episodes_by_technology ===\")\n",
    "technology_res = expert.find_episodes_by_technology(\"Dynamic Tables, View\")\n",
    "print(technology_res)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b74c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test other methods with JSON formatting\n",
    "print(\"=== Testing find_episodes_by_topic ===\")\n",
    "topic_res = expert.find_episodes_by_topic(\"database, Graph\")\n",
    "print(topic_res)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f1bcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Testing find_episodes_by_people ===\")\n",
    "people_res = expert.find_episodes_by_people(\"Prashanth, Sangeetha\")\n",
    "print(people_res)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16bdcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Testing find_episodes_by_concept ===\")\n",
    "concept_res = expert.find_episodes_by_concept(\"graph database, database\")\n",
    "print(concept_res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c6ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "expert.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52aaeb2",
   "metadata": {},
   "source": [
    "## Standalone Expert Tools Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0befbfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vector_graph_tool import VectorGraphSearchTool\n",
    "\n",
    "# Direct usage of the Vector + Graph Search Tool\n",
    "vector_tool = VectorGraphSearchTool()\n",
    "\n",
    "# Test different types of questions\n",
    "questions = [\n",
    "    \"How does KuzuDB improve performance in graph databases?\",\n",
    "    \"What are the key features of Snowflake's dynamic tables?\",\n",
    "    \"Who are the experts discussing data processing optimization?\",\n",
    "    \"What technologies are mentioned in the episodes?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    answer = vector_tool(question, top_k=3)\n",
    "    print(answer)\n",
    "\n",
    "# Clean up\n",
    "vector_tool.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5890411f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bc5728",
   "metadata": {},
   "outputs": [],
   "source": [
    "await db_agent_runner.end_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neo4j-employee-graph",
   "language": "python",
   "name": "neo4j-employee-graph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
